{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 7. Решающие деревья своими руками\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 24.10.18  \n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 04.11.2018 (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 09.11.2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании вам нужно дописать класс для обучения решающего дерева в задаче бинарной классификации с возможностью обработки вещественных и категориальных признаков, а затем протестировать реализацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. (3 балла)__\n",
    "\n",
    "Реализуйте функцию find_best_split, которая по вектору значений признака и вектору ответов вычисляет оптимальное разбиение по этому признаку согласно критерию Джини.\n",
    "\n",
    "Под критерием Джини здесь подразумевается следующая функция:\n",
    "    $$Q(R) = -\\frac {|R_l|}{|R|}H(R_l) -\\frac {|R_r|}{|R|}H(R_r),$$\n",
    "    $R$ — множество объектов, $R_l$ и $R_r$ — объекты, попавшие в левое и правое поддерево,\n",
    "     $H(R) = 1-p_1^2-p_0^2$, $p_1$, $p_0$ — доля объектов класса 1 и 0 соответственно.\n",
    "\n",
    "    Указания:\n",
    "    * Пороги, приводящие к попаданию в одно из поддеревьев пустого множества объектов, не рассматриваются.\n",
    "    * В качестве порогов, нужно брать среднее двух сосдених (при сортировке) значений признака\n",
    "    * Поведение функции в случае константного признака может быть любым.\n",
    "    * При одинаковых приростах Джини нужно выбирать минимальный порог.\n",
    "    * За наличие в функции циклов балл будет снижен. Векторизуйте! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_split(feature_vector, target_vector):\n",
    "    \"\"\"\n",
    "    :param feature_vector: вещественнозначный вектор значений признака\n",
    "    :param target_vector: вектор классов объектов,  len(feature_vector) == len(target_vector)\n",
    "\n",
    "    :return thresholds: отсортированный по возрастанию вектор со всеми возможными порогами, по которым объекты можно\n",
    "     разделить на две различные подвыборки, или поддерева\n",
    "    :return ginis: вектор со значениями критерия Джини для каждого из порогов в thresholds len(ginis) == len(thresholds)\n",
    "    :return threshold_best: оптимальный порог (число)\n",
    "    :return gini_best: оптимальное значение критерия Джини (число)\n",
    "    \"\"\"\n",
    "    # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. (1 балл)__\n",
    "\n",
    "Загрузите таблицу [students.csv](https://drive.google.com/file/d/0B2zoFVYw1rN3a0d0Zm43TzQ4aUU/view?usp=sharing) (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте scatter-графики \"значение признака — класс\" для всех пяти признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. (1 балл)__\n",
    "\n",
    "Исходя из кривых значений критерия Джини, по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой scatter-графиков? Как бы охарактеризовали вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. (3 балла)__\n",
    "\n",
    "Разберитесь с уже написанным кодом в классе DecisionTree. Найдите ошибки в реализации метода \\_fit_node. Напишите функцию \\_predict_node.\n",
    "\n",
    " Построение дерева осуществляется согласно базовому жадному алгоритму, предложенному в [лекции](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture07-trees.pdf) в разделе «Построение дерева». Выбор лучшего разбиения необходимо производить по критерию Джини. Критерий останова: все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку. Ответ в листе: наиболее часто встречающийся класс в листе. Для категориальных признаков выполняется преобразование, описанное в лекции в разделе «Учет категориальных признаков»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, feature_types, max_depth=None, min_samples_split=None, min_samples_leaf=None):\n",
    "        ### feature_types - list consisting of \"real\" and \"categorical\" (same order as in data)\n",
    "        if np.any(list(map(lambda x: x != \"real\" and x != \"categorical\", feature_types))):\n",
    "            raise ValueError(\"There is unknown feature type\")\n",
    "\n",
    "        self._tree = {}\n",
    "        self._feature_types = feature_types\n",
    "        self._max_depth = max_depth # for bonus task\n",
    "        self._min_samples_split = min_samples_split # for bonus task\n",
    "        self._min_samples_leaf = min_samples_leaf # for bonus task\n",
    "\n",
    "    def _fit_node(self, sub_X, sub_y, node):\n",
    "        if np.all(sub_y != sub_y[0]):\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = sub_y[0]\n",
    "            return\n",
    "\n",
    "        feature_best, threshold_best, gini_best, split = None, None, None, None\n",
    "        for feature in range(1, sub_X.shape[1]):\n",
    "            feature_type = self._feature_types[feature]\n",
    "            categories_map = {}\n",
    "\n",
    "            if feature_type == \"real\":\n",
    "                feature_vector = sub_X[:, feature]\n",
    "            elif feature_type == \"categorical\":\n",
    "                counts = Counter(sub_X[:, feature])\n",
    "                clicks = Counter(sub_X[sub_y == 1, feature])\n",
    "                ratio = {}\n",
    "                for key, current_count in counts.items():\n",
    "                    if key in clicks:\n",
    "                        current_click = clicks[key]\n",
    "                    else:\n",
    "                        current_click = 0\n",
    "                    ratio[key] = current_count / current_click\n",
    "                sorted_categories = list(map(lambda x: x[1], sorted(ratio.items(), key=lambda x: x[1])))\n",
    "                categories_map = dict(zip(sorted_categories, list(range(len(sorted_categories)))))\n",
    "\n",
    "                feature_vector = np.array(map(lambda x: categories_map[x], sub_X[:, feature]))\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            if len(feature_vector) == 3:\n",
    "                continue\n",
    "\n",
    "            _, _, threshold, gini = find_best_split(feature_vector, sub_y)\n",
    "            if gini_best is None or gini > gini_best:\n",
    "                feature_best = feature\n",
    "                gini_best = gini\n",
    "                split = feature_vector < threshold\n",
    "\n",
    "                if feature_type == \"real\":\n",
    "                    threshold_best = threshold\n",
    "                elif feature_type == \"Categorical\":\n",
    "                    threshold_best = list(map(lambda x: x[0],\n",
    "                                              filter(lambda x: x[1] < threshold, categories_map.items())))\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "        if feature_best is None:\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = Counter(sub_y).most_common(1)\n",
    "            return\n",
    "\n",
    "        node[\"type\"] = \"nonterminal\"\n",
    "\n",
    "        node[\"feature_split\"] = feature_best\n",
    "        if self._feature_types[feature_best] == \"real\":\n",
    "            node[\"threshold\"] = threshold_best\n",
    "        elif self._feature_types[feature_best] == \"categorical\":\n",
    "            node[\"categories_split\"] = threshold_best\n",
    "        else:\n",
    "            raise ValueError\n",
    "        node[\"left_child\"], node[\"right_child\"] = {}, {}\n",
    "        self._fit_node(sub_X[split], sub_y[split], node[\"left_child\"])\n",
    "        self._fit_node(sub_X[np.logical_not(split)], sub_y[split], node[\"right_child\"])\n",
    "\n",
    "    def _predict_node(self, x, node):\n",
    "        # ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._fit_node(X, y, self._tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicted = []\n",
    "        for x in X:\n",
    "            predicted.append(self._predict_node(x, self._tree))\n",
    "        return np.array(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. (1 балл)__\n",
    "\n",
    "Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). Вам нужно скачать таблицу agaricus-lepiota.data (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), прочитать ее с помощью pandas, применить к каждому столбцу LabelEncoder (из sklearn), чтобы преобразовать строковые имена категорий в натуральные числа. Первый столбец — это целевая переменная (e — edible, p — poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy.\n",
    "\n",
    "У вас должно получиться значение accuracy, равное единице (или очень близкое к единице), и не очень глубокое дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. (1 балл)__\n",
    "Сравните accuracy (на обучении и на контроле) в двух случаях:\n",
    "* DecisionTree, считающий все признаки вещественными\n",
    "* DecisionTree, считающий все признаки категориальными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. (бонусное задание, по 1.5 балла за реализацию+графики для каждого параметра, всего 4.5 баллов, без графиков задание не засчитывается)__\n",
    "\n",
    "Реализуйте в классе DecisionTree поддержку параметров max_depth, min_samples_split и min_samples_leaf по аналогии с DecisionTreeClassifier. Постройте графики зависимости качества предсказания в зависимости от этих параметров для набора данных [tic-tac-toe](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) (классы записаны в последнем столбце)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
